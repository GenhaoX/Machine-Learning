{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、机器学习超参数优化器介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于网格搜索的超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;目前来说sklearn中超参数优化器有四种，分别是GridSearchCV（网格搜索）、RandomizedSearchCV（随机网格搜索）、HalvingSearchCV（对半网格搜索）和HalvingRandomizedSearchCV（对半随机网格搜索）。其中网格搜索是通过枚举搜索出一组最优超参数，枚举的精度最高但效率最低，也就是网格搜索其实是精度最高的搜索算法，但往往伴随着巨大的计算量；而加入了随机网格搜索，则是随机选取了原始参数空间的子空间，然后在这个子空间内进行枚举，尽管还是枚举，但由于参数空间的缩小，计算量也会随之减少，并且伴随着这个参数子空间不断扩大（可人工修改参数），随机网格搜索的计算量和精度都将逼近网格搜索，简而言之随机网格搜索是一种牺牲精度换效率的搜索方式；相比随机网格搜索，对半网格搜索采用了类似锦标赛的筛选机制进行多轮的参数搜索，每一轮输入原始数据一部分数据进行模型训练，并且剔除一半的备选超参数。由于每一轮都只输入了一部分数据，因此不同备选超参数组的评估可能存在一定的误差，但由于每一轮都只剔除一半的超参数组而不是直接选出最优的超参数组，因此也拥有一定的容错性。不难发现，这个过程也像极了RFE过程——每一轮用一个精度不是最高的模型剔除一个最不重要的特征，即保证了执行效率、同时又保证了执行精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果从一个宏观视角来看，随机网格搜索是通过减少备选参数组来减少计算量，而对半网格搜索则是减少带入的数据量，来减少计算量。二者其实都能一定程度提升超参数的搜索效率，但也存在损失精度的风险。当然，如果还想更进一步提高搜索效率，则可以考虑对半搜索和随机搜索的组合——对半随机网格搜索，这种搜索策略实际上就是对半搜索的思路+随机网格搜索的超参数空间，即在一个超参数子空间内进行多轮筛选，每一轮剔除一半的备选超参数组。这种方法的搜索效率是最高的，但同时精度也相对较差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test_OE = X_test_OE.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5277    0\n",
       "5278    0\n",
       "5279    1\n",
       "5280    0\n",
       "5281    0\n",
       "Name: Churn, Length: 5282, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不进行超参数优化时模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier()\n",
    "gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mboosting_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gbdt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnum_leaves\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsample_for_bin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_split_gain\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_child_weight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_child_samples\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsample\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsample_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreg_alpha\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreg_lambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msilent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mimportance_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'split'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      LightGBM classifier.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Construct a gradient boosting model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "boosting_type : str, optional (default='gbdt')\n",
       "    'gbdt', traditional Gradient Boosting Decision Tree.\n",
       "    'dart', Dropouts meet Multiple Additive Regression Trees.\n",
       "    'goss', Gradient-based One-Side Sampling.\n",
       "    'rf', Random Forest.\n",
       "num_leaves : int, optional (default=31)\n",
       "    Maximum tree leaves for base learners.\n",
       "max_depth : int, optional (default=-1)\n",
       "    Maximum tree depth for base learners, <=0 means no limit.\n",
       "learning_rate : float, optional (default=0.1)\n",
       "    Boosting learning rate.\n",
       "    You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
       "    in training using ``reset_parameter`` callback.\n",
       "    Note, that this will ignore the ``learning_rate`` argument in training.\n",
       "n_estimators : int, optional (default=100)\n",
       "    Number of boosted trees to fit.\n",
       "subsample_for_bin : int, optional (default=200000)\n",
       "    Number of samples for constructing bins.\n",
       "objective : str, callable or None, optional (default=None)\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "    Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
       "class_weight : dict, 'balanced' or None, optional (default=None)\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    Use this parameter only for multi-class classification task;\n",
       "    for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
       "    Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
       "    You may want to consider performing probability calibration\n",
       "    (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
       "    The 'balanced' mode uses the values of y to automatically adjust weights\n",
       "    inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "    If None, all classes are supposed to have weight one.\n",
       "    Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
       "    if ``sample_weight`` is specified.\n",
       "min_split_gain : float, optional (default=0.)\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : float, optional (default=1e-3)\n",
       "    Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
       "min_child_samples : int, optional (default=20)\n",
       "    Minimum number of data needed in a child (leaf).\n",
       "subsample : float, optional (default=1.)\n",
       "    Subsample ratio of the training instance.\n",
       "subsample_freq : int, optional (default=0)\n",
       "    Frequency of subsample, <=0 means no enable.\n",
       "colsample_bytree : float, optional (default=1.)\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "reg_alpha : float, optional (default=0.)\n",
       "    L1 regularization term on weights.\n",
       "reg_lambda : float, optional (default=0.)\n",
       "    L2 regularization term on weights.\n",
       "random_state : int, RandomState object or None, optional (default=None)\n",
       "    Random number seed.\n",
       "    If int, this number is used to seed the C++ code.\n",
       "    If RandomState object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
       "    If None, default seeds in C++ code are used.\n",
       "n_jobs : int, optional (default=-1)\n",
       "    Number of parallel threads.\n",
       "silent : bool, optional (default=True)\n",
       "    Whether to print messages while running boosting.\n",
       "importance_type : str, optional (default='split')\n",
       "    The type of feature importance to be filled into ``feature_importances_``.\n",
       "    If 'split', result contains numbers of times the feature is used in a model.\n",
       "    If 'gain', result contains total gains of splits which use the feature.\n",
       "**kwargs\n",
       "    Other parameters for the model.\n",
       "    Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
       "\n",
       "    .. warning::\n",
       "\n",
       "        \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess`` or\n",
       "``objective(y_true, y_pred, group) -> grad, hess``:\n",
       "\n",
       "    y_true : array-like of shape = [n_samples]\n",
       "        The target values.\n",
       "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The predicted values.\n",
       "        Predicted values are returned before any transformation,\n",
       "        e.g. they are raw margin instead of probability of positive class for binary task.\n",
       "    group : array-like\n",
       "        Group/query data.\n",
       "        Only used in the learning-to-rank task.\n",
       "        sum(group) = n_samples.\n",
       "        For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
       "        where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
       "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the first order derivative (gradient) of the loss\n",
       "        with respect to the elements of y_pred for each sample point.\n",
       "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) of the loss\n",
       "        with respect to the elements of y_pred for each sample point.\n",
       "\n",
       "For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
       "If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
       "and you should group grad and hess in this way as well.\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     DaskLGBMClassifier\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LGBMClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体的模型训练过程和sklearn中其他模型一样，通过fit进行训练，并利用predict进行结果输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练模型\n",
    "gbm.fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后输出预测结果，同样可以输出类别结果和概率预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm.predict(X_test_OE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905717531238168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm.score(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787052810902896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|准确率|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LGBM原始模型|0.8905|0.7870|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 确定优化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Name|Description|      \n",
    "|:--:|:--:| \n",
    "|num_leaves|一棵树上的叶子节点数，默认为 31| \n",
    "|max_depth|树的最大深度，默认值为 -1，表示无限制|\n",
    "|min_split_gain|相当于min_impurity_decrease，再分裂所需最小增益。默认值为 0，表示无限制|\n",
    "|min_child_weight|子节点的最小权重和。默认值为 1e-3。较大的 min_child_weight 可以防止过拟合| \n",
    "|min_child_samples|相当于min_samples_leaf，单个叶子节点上的最小样本数量。默认值为 20。较大的 min_child_samples 可以防止过拟合| \n",
    "|boosting_type| 使用的梯度提升算法类型，默认为GBDT|\n",
    "|subsample_for_bin|该参数表示对连续变量进行分箱时（直方图优化过程）抽取样本的个数，默认取值为200000|\n",
    "|learning_rate|学习率，即每次迭代中梯度提升的步长，默认值为 0.1| \n",
    "|n_estimators|迭代次数，即生成的基学习器的数量，默认值为 100|\n",
    "|reg_alpha| L1 正则化系数，默认值为 0|\n",
    "|reg_lambda| L2 正则化系数。默认值为 0|\n",
    "|subsample|模型训练时抽取的样本数量，取值范围为 (0, 1]，表示抽样比例，默认为1.0| \n",
    "|subsample_freq|抽样频率，表示每隔几轮进行一次抽样，默认取值为0，表示不进行随机抽样|\n",
    "|colsample_bytree|在每次迭代（树的构建）时，随机选择特征的比例，取值范围为 (0, 1]，默认为1.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|params|经验最优范围|\n",
    "|:--:|:--:|\n",
    "|num_leaves|range(20, 51, 2)|\n",
    "|max_depth|range(5, 15, 2))| \n",
    "|learning_rate|np.linspace(0.01, 0.2, 5)|\n",
    "|n_estimators|range(10, 160, 70)|\n",
    "|boosting_type|['gbdt', 'goss']|\n",
    "|colsample_bytree|[0.6, 0.8, 1.0]|\n",
    "|reg_alpha|np.linspace(0.01, 0.1, 2)|\n",
    "|reg_lambda|np.linspace(0.01, 0.1, 2)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在确定了要调优哪些参数后，接下来就需要确定每个参数的搜索空间了，这一步也是直接关系到参数搜索效率的关键步骤。首先我们需要对参数搜索需要耗费的时间有基本的判断，才好进行进一步搜索策略的制定，否则极容易出现“仿佛永远等不到搜索停止”的情况出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、基于网格搜索的超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.网格搜索注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先需要明确的是，参数空间内总备选参数组合的数量为各参数取值之积，且随着参数空间内每个参数取值增加而呈现指数级上升，且随着参数空间内参数维度增加（增加新的超参数）呈指数级上升，且二者呈现叠加效应。例如现有参数空间如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数空间有4个备选参数组合\n",
    "parameter_space0 = {\"min_samples_leaf\": range(1, 3),\n",
    "                    \"min_samples_split\": range(1, 3)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则备选的参数组合有$2*2=4$个。而此时如果调整\"min_samples_leaf\": range(1, 4)，则备选参数组合就变成了$2*3=6$个，也就是说,\"min_samples_leaf\"参数搜索范围增加1，造成的搜索次数增加了两次，而非一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数空间有6个备选参数组合\n",
    "parameter_space1 = {\"min_samples_leaf\": range(1, 4),\n",
    "                    \"min_samples_split\": range(1, 3)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "并且，如果我们新增一个超参数维度\"max_depth\": range(1, 4)，则目前总共的备选参数组合就达到了$2*3*3=18$个，也就是说,增加\"min_samples_split\"3个数值，造成的搜索次数增加了18-6=12次，而非3次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数空间有18个备选参数组合\n",
    "parameter_space2 = {\"min_samples_leaf\": range(1, 4),\n",
    "                    \"min_samples_split\": range(1, 3), \n",
    "                    \"max_depth\": range(1, 4)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这种指数级的变化在少量数据情况下可能无法看出“真正的威力”，但如果参数稍微多些或计算过程稍微复杂些，例如假设parameter_space1搜索任务耗时5分钟，而在只增加了一个参数及3个不同取值的情况下，parameter_space2就将耗费15分钟。而如果更复杂些，不是5\\*3=15分钟，而是15\\*3=45分钟呢，甚至是1小时\\*3=3小时呢，参数空间的略微扩大就可能造成搜索时间的指数级增加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 此外，在进行网格搜索时，每一次建模背后还存在5折交叉验证，也就是需要训练5次模型，而每一次建模，都伴随着几十个甚至是上百个决策树模型训练，背后的计算量可想而知。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;介于此，在参数空间设计时就会有这样一个核心问题，那就是参数空间设置小了不确定最优参数是否在这个空间内，参数空间设置大了又不确定何时能算完。这也就是所谓的参数空间设计时面临的“舍罕王赏麦”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.超参数搜索的“凸函数”假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如何解决这个问题，最好的解决方案是“小步迭代、快速调整”。在介绍这种方案之前，要先介绍在超参数调优时大家都会默认的一个假设，那就是超参数的取值和模型效果往往呈现严格“凸函数”的特性，例如假设参数\"min_samples_leaf\"在取值为5时模型效果最好，那么在参数取值为1、2、3、4时，模型效果是依次递增的，而如果参数取值为6、7、8，则模型效果是依次递减的，因此如果我们设计的该参数的搜索空间是\"min_samples_leaf\": range(6, 9)，参数在6、7、8之间取值，则最优结果将会是min_samples_leaf=6，即预设的参数空间的下届，此时我们就需要进一步的移动参数空间，例如改为\"min_samples_leaf\": range(5, 8)，即让参数在5、6、7之间取值，很明显，最终输出的挑选结果将会是min_samples_leaf=5，但此时仍然是搜索空间的下届，因此我们还需要进一步移动搜索空间，即移动至\"min_samples_leaf\": range(4, 7)，即让参数在4、5、6之间取值，此时输出的最优结果将会是min_samples_leaf=5，此时就无需再移动超参数空间了，因为此时的参数空间已经包括了“凸函数”的最小值点，再往左边移动没有任何意义，这个过程如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/01/R5gubzxKyrVeWcd.png\" alt=\"image-20220501213631356\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于单个参数来说，如果呈现出搜索空间包含了最优值点（或者最优值点不在搜索空间的边界上）时，则判断已经找到了最优超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 如果超参数的取值不仅是数值，而是数值和其他类型对象混合的情况，则其他类型对象需要单独作为一个备选项参与搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于单个变量是如此，对于多个变量来说也是如此，若最终超参数搜索结果呈以下状态，则说明我们已经找到了一组最优超参数组："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/01/vWeEnyfFau6soO8.png\" alt=\"image-20220501214514625\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 当然，这种“凸函数假设”其实并没有充份严谨的理论依据，更多的是人们长期实践总结出来的结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.小步前进，快速调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们来看如何通过“小步迭代快速调整”的方法来进行超参数的搜索。在这个策略里，我们每次需要设置一个相对较小的参数搜索空间，然后快速执行一次超参数搜索，并根据超参数搜索结果来调整参数空间，并进行更进一步的超参数搜索，如此往复，直到参数空间内包含了全部参数的最优解为止。就像此前举例的那样，我们不会给\"min_samples_leaf\"一次设置一个非常大的参数搜索范围（如[1,9]），而是每次设置一个更小的搜索范围，通过不断调整这个范围来定位最优解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;既然要反复执行搜索任务，就必然需要一定程度控制单次搜索任务所需要的时间。当然，单次搜索的时间会和CPU、数据量、参数空间大小有关，但一般来说，对于小样本，单次搜索任务最好控制在5-30min内，而对于海量样本，最好也控制在30min-2H内，特殊情况可以适当放宽单次搜索任务的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过无论单次搜索任务耗时或长或短，我们都需要首先有个大概的预判，即本次搜索需要多久，方便我们确定“下次回来看结果”的时间。这里我们以Telco原始数据集为例，来简单测试单次搜索任务需要的时间。这里我们先测试最短单次搜索需要耗费的时间，由于我们需要让每个最优参数落在某个区间的中间，因此每个超参数的取值范围区间至少包含三个数值，例如\"min_samples_leaf\": range(4, 7)、该参数本次搜索至少有三个备选值，此外，如果有些参数包含非数值型参数，则需要在数值参数区间基础上再加上一个非数值型参数，例如\"max_samples\":\\[None, 0.6, 0.5, 0.4\\]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.首次搜索时超参数选取及取值范围的经验依据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|params|经验最优范围|\n",
    "|:--:|:--:|\n",
    "|num_leaves|range(20, 51, 2)|\n",
    "|max_depth|range(5, 15, 2))| \n",
    "|learning_rate|np.linspace(0.01, 0.2, 5)|\n",
    "|n_estimators|range(10, 160, 70)|\n",
    "|boosting_type|['gbdt', 'goss']|\n",
    "|colsample_bytree|[0.6, 0.8, 1.0]|\n",
    "|reg_alpha|np.linspace(0.01, 0.1, 2)|\n",
    "|reg_lambda|np.linspace(0.01, 0.1, 2)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在设置了初始参数后，接下来就是一轮轮搜索与调整了，我们需要大致掌握每一次搜索任务所需要耗费的时间，然后在每次搜索任务结束时及时回到电脑前，准备设置调整参数空间并进行下一次搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.分批训练策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;并且需要注意的是，在进行超参数搜索时，超参数彼此之间是存在交叉影响的，因此如果某次搜索只带入了部分参数进行搜索，那么如果后续增加了其他参数，则再次搜索时这些超参数的最优值也会发生变化。例如某次搜索超参数A在[1,2,3]中取值，找到了最优值A=2，现在如果继续加入超参数B，同时搜索A在[1,2,3]和B在[2,3,4]中最优取值组合，则极有可能出现A的最优取值变成了A=3，此时就要移动A的取值范围了（最优值落在了边界上），接下来如果继续加入超参数C、超参数D、超参数E等，每次加入一个都需要重新搜索一次，这个过程就会变得非常麻烦。当然，需要注意的是，如果只有A和B两个超参数，那么确实可以先搜索A、再搜索B，因为在两个超参数的情况下，二者相互影响有限，单独围绕A搜索出来的最优值2，在加入超参数B之后，A的最优值极有可能仍然在2附近变动，此时我们可以以2为中心设置搜索范围，之前搜索出来的A=2的最优值结果，在同时搜索A和B时仍然具有参考价值。但如果后续加入了C、D、E等更多的超参数，由于超参数彼此之间相互影响也会呈现指数级变动，因此极有可能后续A的取值会偏离2较远，有可能会变成10、20甚至是30，此时反观最开始搜索出来的A=2的最优值，对后续A的搜索过程就变得毫无价值了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此，受此启发，一般来说如果超参数个数较多，则可以分两批、甚至是分三批进行搜索，例如有A、B、C、D、E五个超参数时，可以先搜索A、B、C，在搜索出一组最优值后，再以此为中心创建搜索空间并加入新的D、E两个参数，设置各自对应的搜索空间，并进行第二批搜索。基本过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/02/Utqh532l7dfnJSj.png\" alt=\"image-20220502165350402\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 总之，最终一定要得到一个全部超参数每个最优点都在给定区间范围内的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|params|经验最优范围|\n",
    "|:--:|:--:|\n",
    "|num_leaves|range(20, 51, 2)|\n",
    "|max_depth|range(5, 15, 2))| \n",
    "|learning_rate|np.linspace(0.01, 0.2, 5)|\n",
    "|n_estimators|range(10, 160, 70)|\n",
    "|boosting_type|['gbdt', 'goss']|\n",
    "|colsample_bytree|[0.6, 0.8, 1.0]|\n",
    "|(第一阶段)reg_alpha|np.linspace(0.01, 0.1, 2)|\n",
    "|(第二阶段)reg_lambda|np.linspace(0.01, 0.1, 2)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.LGBM网格搜索调参实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在有了网格搜索优化技巧的基础知识储备后，接下来我们围绕Telco原生数据集来进行随机森林网格搜索实战。一方面测试在原始数据集情况下随机森林模型超参数优化的最好结果，同时我们也将用过一个实例来具体观察我们制定的“小步迭代、快速调整”的调优策略是否能真的帮助我们高效快速的确定最优超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，根据此前介绍，设置初始参数空间并进行搜索，同时计算本次运行的时间。原始数据集总共有19条特征，开方运算与log2计算结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.0575, 0.105, 0.15250000000000002, 0.2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(np.linspace(0.01, 0.2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.77974891662598\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"num_leaves\": range(20, 51, 2), \n",
    "    \"max_depth\": range(5, 15, 2),\n",
    "    \"learning_rate\": list(np.linspace(0.01, 0.2, 5)),\n",
    "    \"n_estimators\": range(10, 160, 70), \n",
    "    \"boosting_type\":['gbdt', 'goss'], \n",
    "    \"colsample_bytree\":[0.6, 0.8, 1.0]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "LGBM_0 = LGBMClassifier(random_state=12)\n",
    "grid_LGBM_0 = GridSearchCV(LGBM_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_LGBM_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后查看当前情况下模型预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078368237722543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8528966300643696, 0.7864849517319704)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_0.score(X_train_OE, y_train), grid_LGBM_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够看出，在进行第一轮超参数搜索时，模型结果的过拟合倾向已经得到了有效抑制，并且对比此前逻辑回归最终的优化结果，目前模型已经得到了一个较好的结果了："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，重点关注本轮搜索得出的超参数最优取值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.6,\n",
       " 'learning_rate': 0.0575,\n",
       " 'max_depth': 11,\n",
       " 'n_estimators': 80,\n",
       " 'num_leaves': 32}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二轮搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.85588598251343\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"num_leaves\": range(30, 35), \n",
    "    \"max_depth\": range(10, 14),\n",
    "    \"learning_rate\": list(np.linspace(0.01, 0.1, 5)),\n",
    "    \"n_estimators\": range(70, 91, 5), \n",
    "    \"boosting_type\":['gbdt', 'goss'], \n",
    "    \"colsample_bytree\":[0.5, 0.6, 0.7]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "LGBM_1 = LGBMClassifier(random_state=12)\n",
    "grid_LGBM_1 = GridSearchCV(LGBM_1, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_LGBM_1.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091622229867264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8511927300265051, 0.7864849517319704)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_1.score(X_train_OE, y_train), grid_LGBM_1.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.6,\n",
       " 'learning_rate': 0.05500000000000001,\n",
       " 'max_depth': 13,\n",
       " 'n_estimators': 70,\n",
       " 'num_leaves': 33}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第三轮搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.77449536323547\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"num_leaves\": range(30, 35), \n",
    "    \"max_depth\": range(12, 17),\n",
    "    \"learning_rate\": list(np.linspace(0.04, 0.07, 5)),\n",
    "    \"n_estimators\": range(60, 81, 2), \n",
    "    \"boosting_type\":['gbdt', 'goss'], \n",
    "    \"colsample_bytree\":[0.55, 0.6, 0.65]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "LGBM_2 = LGBMClassifier(random_state=12)\n",
    "grid_LGBM_2 = GridSearchCV(LGBM_2, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_LGBM_2.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810297690719876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8487315410829231, 0.787052810902896)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_2.score(X_train_OE, y_train), grid_LGBM_2.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.6,\n",
       " 'learning_rate': 0.05500000000000001,\n",
       " 'max_depth': 15,\n",
       " 'n_estimators': 66,\n",
       " 'num_leaves': 33}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第四轮搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.448071002960205\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"num_leaves\": range(32, 37), \n",
    "    \"max_depth\": range(14, 18),\n",
    "    \"learning_rate\": list(np.linspace(0.05, 0.06, 5)),\n",
    "    \"n_estimators\": range(65, 70), \n",
    "    \"boosting_type\":['gbdt', 'goss'], \n",
    "    \"colsample_bytree\":[0.59, 0.6, 0.61]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "LGBM_3 = LGBMClassifier(random_state=12)\n",
    "grid_LGBM_3 = GridSearchCV(LGBM_3, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_LGBM_3.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810297690719876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8487315410829231, 0.787052810902896)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_3.score(X_train_OE, y_train), grid_LGBM_3.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.59,\n",
       " 'learning_rate': 0.055,\n",
       " 'max_depth': 15,\n",
       " 'n_estimators': 66,\n",
       " 'num_leaves': 33}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第五轮搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.1261146068573\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"num_leaves\": range(32, 37), \n",
    "    \"max_depth\": range(14, 18),\n",
    "    \"learning_rate\": list(np.linspace(0.05, 0.06, 5)),\n",
    "    \"n_estimators\": range(65, 70), \n",
    "    \"boosting_type\":['gbdt', 'goss'], \n",
    "    \"colsample_bytree\":[0.585, 0.59, 0.595]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "LGBM_4 = LGBMClassifier(random_state=12)\n",
    "grid_LGBM_4 = GridSearchCV(LGBM_4, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_LGBM_4.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810297690719876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8487315410829231, 0.787052810902896)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_4.score(X_train_OE, y_train), grid_LGBM_4.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.585,\n",
       " 'learning_rate': 0.055,\n",
       " 'max_depth': 15,\n",
       " 'n_estimators': 66,\n",
       " 'num_leaves': 33}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_4.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最终轮搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.39109444618225\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"num_leaves\": range(32, 37), \n",
    "    \"max_depth\": range(14, 18),\n",
    "    \"learning_rate\": list(np.linspace(0.05, 0.06, 5)),\n",
    "    \"n_estimators\": range(65, 70), \n",
    "    \"boosting_type\":['gbdt', 'goss'], \n",
    "    \"colsample_bytree\":[0.585, 0.59, 0.595], \n",
    "    \"reg_alpha\":list(np.linspace(0.01, 0.1, 2))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "LGBM_5 = LGBMClassifier(random_state=12)\n",
    "grid_LGBM_5 = GridSearchCV(LGBM_5, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_LGBM_5.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084039305065795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84967815221507, 0.7904599659284497)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_5.score(X_train_OE, y_train), grid_LGBM_5.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.585,\n",
       " 'learning_rate': 0.052500000000000005,\n",
       " 'max_depth': 14,\n",
       " 'n_estimators': 69,\n",
       " 'num_leaves': 36,\n",
       " 'reg_alpha': 0.01}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_LGBM_5.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|准确率|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LGBM原始模型|0.8905|0.7870|\n",
    "|LGBM+TPE+100|0.8197|0.7864|\n",
    "|LGBM+TPE+200|0.8089|0.7870|\n",
    "|LGBM+TPE+1000|0.80144|0.7890|\n",
    "|LGBM+grid|0.8496|0.7904|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、通过交叉训练进一步提升模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/18/1UAlpgwt2mSbTQ5.png\" alt=\"image-20220518205529331\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后需要单独创建每一轮划分后的训练集和验证集，可以通过如下过程完成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    5 ... 5279 5280 5281]\n",
      "[   0    3    4 ... 5271 5274 5275]\n"
     ]
    }
   ],
   "source": [
    "# 循环一次，切分一次数据集和验证集\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    print(train_part_index)\n",
    "    print(eval_index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.00</td>\n",
       "      <td>241.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>19.00</td>\n",
       "      <td>73.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>84.45</td>\n",
       "      <td>5848.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54.75</td>\n",
       "      <td>1406.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>44.65</td>\n",
       "      <td>472.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>106.30</td>\n",
       "      <td>5487.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>54.10</td>\n",
       "      <td>889.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28</td>\n",
       "      <td>106.15</td>\n",
       "      <td>3152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>20.35</td>\n",
       "      <td>335.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1664.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  PhoneService  MultipleLines  \\\n",
       "1        0.0            0.0      1.0         1.0           1.0            0.0   \n",
       "2        1.0            0.0      0.0         0.0           1.0            0.0   \n",
       "5        0.0            0.0      1.0         1.0           1.0            2.0   \n",
       "6        0.0            0.0      0.0         0.0           1.0            0.0   \n",
       "7        0.0            0.0      0.0         0.0           1.0            0.0   \n",
       "...      ...            ...      ...         ...           ...            ...   \n",
       "5277     1.0            0.0      1.0         0.0           1.0            0.0   \n",
       "5278     0.0            1.0      0.0         0.0           1.0            2.0   \n",
       "5279     0.0            1.0      0.0         0.0           1.0            2.0   \n",
       "5280     0.0            0.0      1.0         1.0           1.0            0.0   \n",
       "5281     1.0            0.0      1.0         1.0           1.0            2.0   \n",
       "\n",
       "      InternetService  OnlineSecurity  OnlineBackup  DeviceProtection  \\\n",
       "1                 1.0             0.0           2.0               0.0   \n",
       "2                 2.0             1.0           1.0               1.0   \n",
       "5                 1.0             2.0           0.0               2.0   \n",
       "6                 0.0             0.0           2.0               2.0   \n",
       "7                 0.0             0.0           0.0               0.0   \n",
       "...               ...             ...           ...               ...   \n",
       "5277              1.0             2.0           2.0               2.0   \n",
       "5278              0.0             2.0           0.0               0.0   \n",
       "5279              1.0             0.0           2.0               2.0   \n",
       "5280              2.0             1.0           1.0               1.0   \n",
       "5281              2.0             1.0           1.0               1.0   \n",
       "\n",
       "      TechSupport  StreamingTV  StreamingMovies  Contract  PaperlessBilling  \\\n",
       "1             2.0          0.0              0.0       0.0               1.0   \n",
       "2             1.0          1.0              1.0       0.0               0.0   \n",
       "5             0.0          0.0              0.0       1.0               0.0   \n",
       "6             0.0          0.0              0.0       0.0               1.0   \n",
       "7             0.0          0.0              0.0       0.0               1.0   \n",
       "...           ...          ...              ...       ...               ...   \n",
       "5277          2.0          2.0              2.0       2.0               1.0   \n",
       "5278          0.0          0.0              0.0       0.0               1.0   \n",
       "5279          0.0          2.0              2.0       0.0               1.0   \n",
       "5280          1.0          1.0              1.0       1.0               0.0   \n",
       "5281          1.0          1.0              1.0       2.0               1.0   \n",
       "\n",
       "      PaymentMethod  tenure  MonthlyCharges  TotalCharges  \n",
       "1               2.0       3           80.00        241.30  \n",
       "2               3.0       4           19.00         73.45  \n",
       "5               0.0      69           84.45       5848.60  \n",
       "6               1.0      26           54.75       1406.90  \n",
       "7               3.0      11           44.65        472.25  \n",
       "...             ...     ...             ...           ...  \n",
       "5277            2.0      52          106.30       5487.00  \n",
       "5278            2.0      16           54.10        889.00  \n",
       "5279            2.0      28          106.15       3152.50  \n",
       "5280            1.0      15           20.35        335.95  \n",
       "5281            0.0      68           24.00       1664.30  \n",
       "\n",
       "[4225 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_OE.loc[train_part_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   1,    2,    5, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    3, ..., 5275, 5277, 5281]),\n",
       " array([   0,    2,    3, ..., 5278, 5279, 5280])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_part_index_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于clf的交叉训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = []\n",
    "kf = KFold(n_splits=3, random_state=11, shuffle=True)\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    # 在训练集上训练\n",
    "    X_train_part = X_train_OE.loc[train_part_index]\n",
    "    y_train_part = y_train.loc[train_part_index]\n",
    "    clf.fit(X_train_part, y_train_part)\n",
    "    # 将测试集上预测结果填入predict数据集\n",
    "    test_predict.append(clf.predict_proba(X_test_OE)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.0307229 , 0.22867404, 0.02423184, ..., 0.11940864, 0.62738151,\n",
       "        0.1207684 ]),\n",
       " array([0.02976366, 0.34260337, 0.01902775, ..., 0.17791131, 0.61817475,\n",
       "        0.14663852]),\n",
       " array([0.03098913, 0.30166054, 0.01886396, ..., 0.19259972, 0.66194877,\n",
       "        0.13475334])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0304919 , 0.29097931, 0.02070785, ..., 0.16330656, 0.63583501,\n",
       "       0.13405342])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.array(test_predict).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (np.array(test_predict).mean(0) >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1756    0\n",
       "1757    0\n",
       "1758    0\n",
       "1759    1\n",
       "1760    0\n",
       "Name: Churn, Length: 1761, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910278250993753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_score(res, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|准确率|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LGBM原始模型|0.8905|0.7870|\n",
    "|LGBM+TPE+100|0.8197|0.7864|\n",
    "|LGBM+TPE+200|0.8089|0.7870|\n",
    "|LGBM+TPE+1000|0.80144|0.7890|\n",
    "|LGBM+grid|0.8496|0.7904|\n",
    "|LGBM+TPE+1000|交叉训练|0.7910|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于grid_LGBM_5的交叉训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = []\n",
    "kf = KFold(n_splits=3, random_state=11, shuffle=True)\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    # 在训练集上训练\n",
    "    X_train_part = X_train_OE.loc[train_part_index]\n",
    "    y_train_part = y_train.loc[train_part_index]\n",
    "    grid_LGBM_5.best_estimator_.fit(X_train_part, y_train_part)\n",
    "    # 将测试集上预测结果填入predict数据集\n",
    "    test_predict.append(grid_LGBM_5.predict_proba(X_test_OE)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.02279709, 0.19923274, 0.02415225, ..., 0.10446081, 0.65781821,\n",
       "        0.06689876]),\n",
       " array([0.0228167 , 0.37510663, 0.01549221, ..., 0.20079375, 0.62692221,\n",
       "        0.10498177]),\n",
       " array([0.02746028, 0.33716952, 0.01307974, ..., 0.2329891 , 0.65084317,\n",
       "        0.08372255])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02435802, 0.30383629, 0.01757473, ..., 0.17941455, 0.64519453,\n",
       "       0.08520103])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.array(test_predict).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (np.array(test_predict).mean(0) >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1756    0\n",
       "1757    0\n",
       "1758    0\n",
       "1759    1\n",
       "1760    0\n",
       "Name: Churn, Length: 1761, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921635434412265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_score(res, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|准确率|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LGBM原始模型|0.8905|0.7870|\n",
    "|LGBM+TPE+100|0.8197|0.7864|\n",
    "|LGBM+TPE+200|0.8089|0.7870|\n",
    "|LGBM+TPE+1000|0.80144|0.7890|\n",
    "|LGBM+grid|0.8496|0.7904|\n",
    "|LGBM+TPE+1000|交叉训练|0.7910|\n",
    "|LGBM+grid|交叉训练|0.7921|"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
